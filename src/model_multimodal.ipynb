{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input, optimizers, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load dataset and relevant columns\n",
    "df = pd.read_csv(\"../data/nutrition_filtered.csv\", usecols=[0, 1, 7],\n",
    "                 header=0, names=[\"dish_id\", \"calories\", \"text\"])\n",
    "df[\"image_path\"] = df[\"dish_id\"].apply(lambda x: f\"../data/images/{x}.png\")\n",
    "\n",
    "# File containing test data\n",
    "with open(f\"../data/fold_1.txt\") as f:\n",
    "    test_ids = set(line.strip() for line in f)\n",
    "train_ids = set(df[\"dish_id\"]) - test_ids\n",
    "\n",
    "train_df = df[df[\"dish_id\"].isin(train_ids)].copy()\n",
    "test_df  = df[df[\"dish_id\"].isin(test_ids)].copy() \n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=20)\n",
    "text_vectorizer.adapt(train_df[\"text\"])\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "def preprocess(inputs, label):\n",
    "    path, text = inputs\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, 0.1)\n",
    "    img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0\n",
    "    text = text_vectorizer(text)\n",
    "    return (img, text), label\n",
    "\n",
    "def make_dataset(df, batch_size=16, shuffle=True):\n",
    "    paths = df[\"image_path\"].values\n",
    "    texts = df[\"text\"].values\n",
    "    labels = df[\"calories\"].values.astype(\"float32\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((paths, texts), labels))\n",
    "    ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dataset(train_df, shuffle=True)\n",
    "val_ds   = make_dataset(test_df,  shuffle=False)  # keep order!\n",
    "\n",
    "# Defining model variables\n",
    "vocab_size = len(text_vectorizer.get_vocabulary())\n",
    "emb_dim = 128\n",
    "\n",
    "# Image branch\n",
    "img_input = Input(shape=(224, 224, 3))\n",
    "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", pooling=\"avg\")\n",
    "base_model.trainable = False\n",
    "img_features = base_model(img_input)\n",
    "\n",
    "# Text branch\n",
    "text_input = Input(shape=(20,), dtype='int32')\n",
    "text_emb = layers.Embedding(vocab_size, emb_dim)(text_input)\n",
    "text_features = layers.GlobalAveragePooling1D()(text_emb)\n",
    "\n",
    "# Cross-attention (image attends to text)\n",
    "proj_img  = layers.Dense(256)(img_features)\n",
    "proj_text = layers.Dense(256)(text_features)\n",
    "proj_img  = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(proj_img)\n",
    "proj_text = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(proj_text)\n",
    "cross_att = layers.MultiHeadAttention(num_heads=4, key_dim=64)(\n",
    "    query=proj_img, value=proj_text, key=proj_text)\n",
    "\n",
    "fused = layers.Flatten()(cross_att)\n",
    "combined = layers.Concatenate()([fused, img_features, text_features])\n",
    "x = layers.Dense(128, activation='relu')(combined)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "out = layers.Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[img_input, text_input], outputs=out)\n",
    "model.compile(optimizer=optimizers.Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train\n",
    "model.fit(train_ds, epochs=10, verbose=0)\n",
    "\n",
    "# Test stage\n",
    "preds = model.predict(val_ds, verbose=0).flatten()\n",
    "y_true = test_df[\"calories\"].values.astype(float)\n",
    "dish_ids = test_df[\"dish_id\"].values\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_true, preds)\n",
    "r2  = r2_score(y_true, preds)\n",
    "\n",
    "# Per-dish CSV export\n",
    "out_df = pd.DataFrame({\n",
    "    \"dish_id\": dish_ids,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": preds,\n",
    "    \"abs_error\": np.abs(y_true - preds)\n",
    "})\n",
    "out_df.to_csv(f\"../data/multimodal_errors.csv\", index=False)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== Results ===\")\n",
    "print(f\"MAE = {mae:.2f} kcal | RÂ² = {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
